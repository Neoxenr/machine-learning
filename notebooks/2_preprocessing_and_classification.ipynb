{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140787 entries, 0 to 140786\n",
      "Columns: 121 entries, MinTemp to WindDir3pm_without_value\n",
      "dtypes: float64(16), int64(105)\n",
      "memory usage: 130.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как датасет содержит большое количество записей, то, для улучшения времени работы алгоритмов, возьмем лишь 10000 записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[:-10000], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "      <th>WindDir3pm_without_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130787</th>\n",
       "      <td>6.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130788</th>\n",
       "      <td>7.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130789</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130790</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130791</th>\n",
       "      <td>-2.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "130787      6.6     11.1       1.4     5.468232  7.611178           22.0   \n",
       "130788      7.6     13.8      13.0     5.468232  7.611178           46.0   \n",
       "130789      5.0     10.3       0.0     5.468232  7.611178           46.0   \n",
       "130790     -1.9     10.7       0.0     5.468232  7.611178           17.0   \n",
       "130791     -2.9     10.0       0.3     5.468232  7.611178           13.0   \n",
       "\n",
       "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
       "130787           9.0          11.0         94.0         95.0  ...   \n",
       "130788           4.0          24.0         96.0         67.0  ...   \n",
       "130789          17.0          20.0         75.0         64.0  ...   \n",
       "130790           4.0           7.0         96.0         52.0  ...   \n",
       "130791           0.0           4.0         97.0         51.0  ...   \n",
       "\n",
       "        WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  \\\n",
       "130787              0             0              1               0   \n",
       "130788              0             0              0               1   \n",
       "130789              0             0              0               1   \n",
       "130790              0             0              0               0   \n",
       "130791              1             0              0               0   \n",
       "\n",
       "        WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  \\\n",
       "130787               0              0             0               0   \n",
       "130788               0              0             0               0   \n",
       "130789               0              0             0               0   \n",
       "130790               1              0             0               0   \n",
       "130791               0              0             0               0   \n",
       "\n",
       "        WindDir3pm_WSW  WindDir3pm_without_value  \n",
       "130787               0                         0  \n",
       "130788               0                         0  \n",
       "130789               0                         0  \n",
       "130790               0                         0  \n",
       "130791               0                         0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinTemp                     0\n",
       "MaxTemp                     0\n",
       "Rainfall                    0\n",
       "Evaporation                 0\n",
       "Sunshine                    0\n",
       "                           ..\n",
       "WindDir3pm_SW               0\n",
       "WindDir3pm_W                0\n",
       "WindDir3pm_WNW              0\n",
       "WindDir3pm_WSW              0\n",
       "WindDir3pm_without_value    0\n",
       "Length: 121, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем в матрицу X все значения признаков кроме целевого, а в матрицу y - значения целевого признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'RainTomorrow']\n",
    "y = df.loc[:, 'RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "      <th>WindDir3pm_without_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130787</th>\n",
       "      <td>6.6</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130788</th>\n",
       "      <td>7.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130789</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130790</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130791</th>\n",
       "      <td>-2.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.468232</td>\n",
       "      <td>7.611178</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "130787      6.6     11.1       1.4     5.468232  7.611178           22.0   \n",
       "130788      7.6     13.8      13.0     5.468232  7.611178           46.0   \n",
       "130789      5.0     10.3       0.0     5.468232  7.611178           46.0   \n",
       "130790     -1.9     10.7       0.0     5.468232  7.611178           17.0   \n",
       "130791     -2.9     10.0       0.3     5.468232  7.611178           13.0   \n",
       "\n",
       "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
       "130787           9.0          11.0         94.0         95.0  ...   \n",
       "130788           4.0          24.0         96.0         67.0  ...   \n",
       "130789          17.0          20.0         75.0         64.0  ...   \n",
       "130790           4.0           7.0         96.0         52.0  ...   \n",
       "130791           0.0           4.0         97.0         51.0  ...   \n",
       "\n",
       "        WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  \\\n",
       "130787              0             0              1               0   \n",
       "130788              0             0              0               1   \n",
       "130789              0             0              0               1   \n",
       "130790              0             0              0               0   \n",
       "130791              1             0              0               0   \n",
       "\n",
       "        WindDir3pm_SSW  WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  \\\n",
       "130787               0              0             0               0   \n",
       "130788               0              0             0               0   \n",
       "130789               0              0             0               0   \n",
       "130790               1              0             0               0   \n",
       "130791               0              0             0               0   \n",
       "\n",
       "        WindDir3pm_WSW  WindDir3pm_without_value  \n",
       "130787               0                         0  \n",
       "130788               0                         0  \n",
       "130789               0                         0  \n",
       "130790               0                         0  \n",
       "130791               0                         0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130787    1\n",
       "130788    0\n",
       "130789    0\n",
       "130790    0\n",
       "130791    0\n",
       "Name: RainTomorrow, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающуюся и тестовую. Воспользуемся методом train_test_split из модуля sklearn.model_selection. В обучающуюся выборку попадет 80 процентов исходных данных, а в тестовую - соответсвенно 20 процентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как значения признаков различаются, то есть некоторые признаки имеют большие значения, которые значительно отличаются от других, нужно применить масштабирование. Воспользуемся модулем sklearn.preprocessing и StandardScale. Для этого, сначала настроим объект scaler, а потом применим масштабирование к обучающейся и тестовой выборке, то есть X_train и X_test соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.26466709,  0.71123918, -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326],\n",
       "       [ 0.04260789,  0.57624829, -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326],\n",
       "       [ 0.27306412,  0.5612493 , -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326],\n",
       "       ...,\n",
       "       [-0.12383273,  0.1862746 , -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326],\n",
       "       [-0.52072958,  0.41125942, -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326],\n",
       "       [-1.91627012, -1.67359991, -0.23873597, ..., -0.29862403,\n",
       "        -0.14910929, -0.07177326]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью метода k-ближайших соседей. В качестве параметра передадим в классификатор параметр \"n_neighbors\". Классификатор будет искать кратчайшее расстояние между объектами и 3-мя ближайшими к ним соседям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем работу модели на тестовой выборке, а также посмотрим на качество работы модели с помощью  classification_report и confusion_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1601   65]\n",
      " [ 230  104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      1666\n",
      "           1       0.62      0.31      0.41       334\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.74      0.64      0.66      2000\n",
      "weighted avg       0.83      0.85      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью классификатора дерева решений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем работу модели на тестовой выборке, а также посмотрим на качество работы модели с помощью  classification_report и confusion_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1487  179]\n",
      " [ 147  187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      1666\n",
      "           1       0.51      0.56      0.53       334\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.71      0.73      0.72      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что данный алгоритм отработал лучше, чем предыдущий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью наивного байесовского классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем работу модели на тестовой выборке, а также посмотрим на качество работы модели с помощью  classification_report и confusion_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1332  334]\n",
      " [  97  237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1666\n",
      "           1       0.42      0.71      0.52       334\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.67      0.75      0.69      2000\n",
      "weighted avg       0.85      0.78      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По матрице можно заметить, что полнота (recall) значительно выше, чем у 2-х предыдущих моделей. Это значит, что классификатор нашел большую долю объектов положительного класса из всех объектов положительного класса, по сравнению с 2-мя предыдущими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью метода опорных векторов. Для ускорения обучения модели используется LinearSVC, который работает значительно быстрее, чем стандартный SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем работу модели на тестовой выборке, а также посмотрим на качество работы модели с помощью classification_report и confusion_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1610   56]\n",
      " [ 151  183]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1666\n",
      "           1       0.77      0.55      0.64       334\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.84      0.76      0.79      2000\n",
      "weighted avg       0.89      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что классификатор дал наилучших результат из всех обученных предыдущих моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с помощью логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем работу модели на тестовой выборке, а также посмотрим на качество работы модели с помощью classification_report и confusion_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1604   62]\n",
      " [ 140  194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1666\n",
      "           1       0.76      0.58      0.66       334\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.84      0.77      0.80      2000\n",
      "weighted avg       0.89      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель отработала лучше всех, то есть дала наилучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поищем оптимальные гиперпараметры для моделей. Подобрав оптимальные гиперпараметры, мы можем значительно улучшить качество модели. Для подбора оптимальных гиперпараметрво воспользуемся GridSearchCV, которому будем в качестве параметров передавать обучаемую модель и набор гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного классификатора будем искать оптимальный гиперпараметр \"n_neighbors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': [1, 2, 3]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_estimator_ узнаем наилучшую модель, полученную в результате поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью best_score_ узнаем средний кросс-валидированный балл best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8591249999999999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_params_ узнаем лучшие найденные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью cs_results_ узнаем словарь всех метрик оценки из GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.19701791, 0.19798493, 0.25013304]),\n",
       " 'std_fit_time': array([0.00497959, 0.00322396, 0.02948003]),\n",
       " 'mean_score_time': array([1.92432795, 1.9947206 , 2.71927657]),\n",
       " 'std_score_time': array([0.07762017, 0.04944012, 0.03178581]),\n",
       " 'param_n_neighbors': masked_array(data=[1, 2, 3],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}],\n",
       " 'split0_test_score': array([0.83875 , 0.853125, 0.84875 ]),\n",
       " 'split1_test_score': array([0.835625, 0.855625, 0.8625  ]),\n",
       " 'split2_test_score': array([0.840625, 0.86375 , 0.85625 ]),\n",
       " 'split3_test_score': array([0.8375, 0.8575, 0.8625]),\n",
       " 'split4_test_score': array([0.83625 , 0.86375 , 0.865625]),\n",
       " 'mean_test_score': array([0.83775 , 0.85875 , 0.859125]),\n",
       " 'std_test_score': array([0.00179409, 0.00431205, 0.0060156 ]),\n",
       " 'rank_test_score': array([3, 2, 1])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели после подборки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1601   65]\n",
      " [ 230  104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      1666\n",
      "           1       0.62      0.31      0.41       334\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.74      0.64      0.66      2000\n",
      "weighted avg       0.83      0.85      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели после подбора гиперпараметров никак не улучшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного классификатора будем искать оптимальные гиперпараметры \"criterion\", \"splitter\", \"min_samples_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'min_samples_split': [2, 10, 20, 30, 50],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'min_samples_split' : [2, 10, 20, 30, 50]\n",
    "}\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf = GridSearchCV(dtc, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_estimator_ узнаем наилучшую модель, полученную в результате поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', min_samples_split=50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью best_score_ узнаем средний кросс-валидированный балл best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_params_ узнаем лучшие найденные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'min_samples_split': 50, 'splitter': 'best'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью cs_results_ узнаем словарь всех метрик оценки из GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.11561728, 0.07240787, 0.10970778, 0.05300283, 0.10280724,\n",
       "        0.04780326, 0.10004377, 0.04694881, 0.1041285 , 0.04259896,\n",
       "        0.09013481, 0.04160218, 0.08360624, 0.04300323, 0.08300605,\n",
       "        0.03920321, 0.07811174, 0.03880315, 0.07490721, 0.03460073]),\n",
       " 'std_fit_time': array([0.01074757, 0.01865921, 0.00577618, 0.00740289, 0.0044005 ,\n",
       "        0.00263915, 0.00223375, 0.00406045, 0.00554181, 0.00149573,\n",
       "        0.00466054, 0.00102116, 0.00338333, 0.00384739, 0.00244888,\n",
       "        0.00132686, 0.00264818, 0.00271274, 0.0030072 , 0.00320166]),\n",
       " 'mean_score_time': array([0.00099826, 0.00120149, 0.00120039, 0.00100131, 0.00120001,\n",
       "        0.00140109, 0.00099993, 0.00100036, 0.00099983, 0.00100083,\n",
       "        0.0018003 , 0.00100093, 0.00102315, 0.00120068, 0.0012002 ,\n",
       "        0.0010005 , 0.00120068, 0.00100017, 0.00120072, 0.00100031]),\n",
       " 'std_score_time': array([5.86141300e-06, 3.99901938e-04, 4.00448215e-04, 5.51978917e-07,\n",
       "        4.00759077e-04, 4.90058184e-04, 1.38200538e-06, 5.30983387e-07,\n",
       "        8.74056949e-07, 8.44957597e-07, 3.99947916e-04, 1.38529196e-06,\n",
       "        4.75255250e-05, 4.00067086e-04, 3.99710408e-04, 6.50319180e-07,\n",
       "        4.00901560e-04, 1.10806942e-06, 4.00045443e-04, 1.14440918e-06]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 10, 10, 20, 20, 30, 30, 50, 50, 2, 2, 10, 10, 20,\n",
       "                    20, 30, 30, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_splitter': masked_array(data=['best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random', 'best', 'random', 'best', 'random',\n",
       "                    'best', 'random'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini', 'min_samples_split': 2, 'splitter': 'best'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 2, 'splitter': 'random'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 10, 'splitter': 'best'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 10, 'splitter': 'random'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 20, 'splitter': 'best'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 20, 'splitter': 'random'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 30, 'splitter': 'best'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 30, 'splitter': 'random'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 50, 'splitter': 'best'},\n",
       "  {'criterion': 'gini', 'min_samples_split': 50, 'splitter': 'random'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 2, 'splitter': 'best'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 2, 'splitter': 'random'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 10, 'splitter': 'best'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 10, 'splitter': 'random'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 20, 'splitter': 'best'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 20, 'splitter': 'random'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 30, 'splitter': 'best'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 30, 'splitter': 'random'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 50, 'splitter': 'best'},\n",
       "  {'criterion': 'entropy', 'min_samples_split': 50, 'splitter': 'random'}],\n",
       " 'split0_test_score': array([0.863125, 0.835625, 0.85875 , 0.866875, 0.87125 , 0.87875 ,\n",
       "        0.870625, 0.873125, 0.8725  , 0.8725  , 0.858125, 0.871875,\n",
       "        0.874375, 0.86625 , 0.871875, 0.85875 , 0.88    , 0.863125,\n",
       "        0.88    , 0.88875 ]),\n",
       " 'split1_test_score': array([0.846875, 0.8475  , 0.865   , 0.858125, 0.8575  , 0.87    ,\n",
       "        0.868125, 0.870625, 0.865625, 0.87125 , 0.858125, 0.855625,\n",
       "        0.851875, 0.860625, 0.85875 , 0.859375, 0.859375, 0.870625,\n",
       "        0.874375, 0.8775  ]),\n",
       " 'split2_test_score': array([0.855625, 0.86625 , 0.860625, 0.87125 , 0.86875 , 0.870625,\n",
       "        0.8725  , 0.87875 , 0.88375 , 0.885625, 0.865   , 0.870625,\n",
       "        0.863125, 0.8675  , 0.87    , 0.856875, 0.87375 , 0.873125,\n",
       "        0.883125, 0.880625]),\n",
       " 'split3_test_score': array([0.87    , 0.849375, 0.87125 , 0.865625, 0.889375, 0.866875,\n",
       "        0.8925  , 0.869375, 0.89375 , 0.875625, 0.856875, 0.853125,\n",
       "        0.865   , 0.8625  , 0.87625 , 0.87875 , 0.8775  , 0.87625 ,\n",
       "        0.8875  , 0.88125 ]),\n",
       " 'split4_test_score': array([0.850625, 0.845   , 0.8675  , 0.861875, 0.86875 , 0.85625 ,\n",
       "        0.874375, 0.876875, 0.878125, 0.88    , 0.8625  , 0.845   ,\n",
       "        0.869375, 0.859375, 0.875625, 0.854375, 0.876875, 0.868125,\n",
       "        0.885   , 0.880625]),\n",
       " 'mean_test_score': array([0.85725 , 0.84875 , 0.864625, 0.86475 , 0.871125, 0.8685  ,\n",
       "        0.875625, 0.87375 , 0.87875 , 0.877   , 0.860125, 0.85925 ,\n",
       "        0.86475 , 0.86325 , 0.8705  , 0.861625, 0.8735  , 0.87025 ,\n",
       "        0.882   , 0.88175 ]),\n",
       " 'std_test_score': array([0.00838153, 0.00994516, 0.00453459, 0.00446514, 0.01029563,\n",
       "        0.00727367, 0.00868728, 0.00357946, 0.00960957, 0.00526486,\n",
       "        0.00309738, 0.01041633, 0.00751665, 0.00314742, 0.00631714,\n",
       "        0.00873749, 0.00733783, 0.00446514, 0.00453114, 0.00373748]),\n",
       " 'rank_test_score': array([19, 20, 14, 12,  8, 11,  5,  6,  3,  4, 17, 18, 13, 15,  9, 16,  7,\n",
       "        10,  1,  2])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели после подборки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1567   99]\n",
      " [ 132  202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1666\n",
      "           1       0.67      0.60      0.64       334\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.80      0.77      0.78      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сравнению с предыдущей моделью, качество улучшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного классификатора будем искать оптимальный гиперпараметр \"var_smoothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': [1e-11, 1e-10, 1e-09, 1e-08, 1e-07,\n",
       "                                           1e-06, 1e-05]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"var_smoothing\": [1e-11, 1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "clf = GridSearchCV(gnb, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_estimator_ узнаем наилучшую модель, полученную в результате поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(var_smoothing=1e-11)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью best_score_ узнаем средний кросс-валидированный балл best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7901250000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_params_ узнаем лучшие найденные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 1e-11}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью cs_results_ узнаем словарь всех метрик оценки из GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.02330298, 0.02238889, 0.02300262, 0.02360229, 0.02160115,\n",
       "        0.02130251, 0.02220235]),\n",
       " 'std_fit_time': array([0.00074908, 0.00103678, 0.00167431, 0.00048963, 0.00048984,\n",
       "        0.00040004, 0.00116653]),\n",
       " 'mean_score_time': array([0.00540085, 0.00500059, 0.00580001, 0.0064002 , 0.00520048,\n",
       "        0.00540066, 0.0059999 ]),\n",
       " 'std_score_time': array([4.90213771e-04, 5.43678010e-07, 7.47819141e-04, 4.89804070e-04,\n",
       "        4.00018990e-04, 4.90465972e-04, 3.56832255e-07]),\n",
       " 'param_var_smoothing': masked_array(data=[1e-11, 1e-10, 1e-09, 1e-08, 1e-07, 1e-06, 1e-05],\n",
       "              mask=[False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'var_smoothing': 1e-11},\n",
       "  {'var_smoothing': 1e-10},\n",
       "  {'var_smoothing': 1e-09},\n",
       "  {'var_smoothing': 1e-08},\n",
       "  {'var_smoothing': 1e-07},\n",
       "  {'var_smoothing': 1e-06},\n",
       "  {'var_smoothing': 1e-05}],\n",
       " 'split0_test_score': array([0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875,\n",
       "        0.796875]),\n",
       " 'split1_test_score': array([0.77625, 0.77625, 0.77625, 0.77625, 0.77625, 0.77625, 0.77625]),\n",
       " 'split2_test_score': array([0.796875, 0.796875, 0.796875, 0.796875, 0.796875, 0.796875,\n",
       "        0.796875]),\n",
       " 'split3_test_score': array([0.79375, 0.79375, 0.79375, 0.79375, 0.79375, 0.79375, 0.79375]),\n",
       " 'split4_test_score': array([0.786875, 0.786875, 0.786875, 0.786875, 0.786875, 0.786875,\n",
       "        0.786875]),\n",
       " 'mean_test_score': array([0.790125, 0.790125, 0.790125, 0.790125, 0.790125, 0.790125,\n",
       "        0.790125]),\n",
       " 'std_test_score': array([0.0078402, 0.0078402, 0.0078402, 0.0078402, 0.0078402, 0.0078402,\n",
       "        0.0078402]),\n",
       " 'rank_test_score': array([1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели после подборки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1332  334]\n",
      " [  97  237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      1666\n",
      "           1       0.42      0.71      0.52       334\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.67      0.75      0.69      2000\n",
      "weighted avg       0.85      0.78      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели после подбора гиперпараметров никак не улучшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного классификатора будем искать оптимальные гиперпараметры \"penalty\", \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 821, in _get_liblinear_solver_type\n",
      "    raise ValueError('Unsupported set of arguments: %s, '\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\", line 233, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 965, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 804, in _get_liblinear_solver_type\n",
      "    _solver_pen = _solver_type_dict.get(loss, None)\n",
      "TypeError: unhashable type: 'list'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(),\n",
       "             param_grid={'loss': ['hinge', ['squared_hinge']],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'loss' : ['hinge', ['squared_hinge']]\n",
    "}\n",
    "\n",
    "svc = svm.LinearSVC()\n",
    "\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_estimator_ узнаем наилучшую модель, полученную в результате поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(loss='hinge')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью best_score_ узнаем средний кросс-валидированный балл best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.898125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_params_ узнаем лучшие найденные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'hinge', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью cs_results_ узнаем словарь всех метрик оценки из GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00790305, 0.37583189, 0.00860057, 0.00840001]),\n",
       " 'std_fit_time': array([0.0009195 , 0.03865819, 0.00048938, 0.00048926]),\n",
       " 'mean_score_time': array([0.        , 0.00120234, 0.        , 0.        ]),\n",
       " 'std_score_time': array([0.        , 0.00039947, 0.        , 0.        ]),\n",
       " 'param_loss': masked_array(data=['hinge', 'hinge', list(['squared_hinge']),\n",
       "                    list(['squared_hinge'])],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'loss': 'hinge', 'penalty': 'l1'},\n",
       "  {'loss': 'hinge', 'penalty': 'l2'},\n",
       "  {'loss': ['squared_hinge'], 'penalty': 'l1'},\n",
       "  {'loss': ['squared_hinge'], 'penalty': 'l2'}],\n",
       " 'split0_test_score': array([    nan, 0.90125,     nan,     nan]),\n",
       " 'split1_test_score': array([    nan, 0.89125,     nan,     nan]),\n",
       " 'split2_test_score': array([     nan, 0.895625,      nan,      nan]),\n",
       " 'split3_test_score': array([nan, 0.9, nan, nan]),\n",
       " 'split4_test_score': array([   nan, 0.9025,    nan,    nan]),\n",
       " 'mean_test_score': array([     nan, 0.898125,      nan,      nan]),\n",
       " 'std_test_score': array([       nan, 0.00414578,        nan,        nan]),\n",
       " 'rank_test_score': array([2, 1, 3, 4])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели после подборки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1614   52]\n",
      " [ 150  184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94      1666\n",
      "           1       0.78      0.55      0.65       334\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.85      0.76      0.79      2000\n",
      "weighted avg       0.89      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели после подбора гиперпараметров улучшилось, но незначительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для данного классификатора будем искать оптимальные гиперпараметры \"penalty\", \"С\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\vano_\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'penalty': ['l1', 'l2'],\n",
    "               'C': [0.1, 1, 10]               \n",
    "              }\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_estimator_ узнаем наилучшую модель, полученную в результате поиска по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью best_score_ узнаем средний кросс-валидированный балл best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью best_params_ узнаем лучшие найденные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью cs_results_ узнаем словарь всех метрик оценки из GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.0052074 , 0.10785551, 0.00500169, 0.15073977, 0.00500088,\n",
       "        0.17901578]),\n",
       " 'std_fit_time': array([0.00041182, 0.00486053, 0.00063271, 0.01673791, 0.00063279,\n",
       "        0.01982848]),\n",
       " 'mean_score_time': array([0.        , 0.00060081, 0.        , 0.00099859, 0.        ,\n",
       "        0.00101209]),\n",
       " 'std_score_time': array([0.00000000e+00, 4.90563686e-04, 0.00000000e+00, 8.20381667e-07,\n",
       "        0.00000000e+00, 2.38614002e-05]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 1, 1, 10, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2'],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'}],\n",
       " 'split0_test_score': array([     nan, 0.90125 ,      nan, 0.90125 ,      nan, 0.900625]),\n",
       " 'split1_test_score': array([     nan, 0.889375,      nan, 0.89125 ,      nan, 0.890625]),\n",
       " 'split2_test_score': array([     nan, 0.894375,      nan, 0.895625,      nan, 0.896875]),\n",
       " 'split3_test_score': array([     nan, 0.9     ,      nan, 0.90375 ,      nan, 0.903125]),\n",
       " 'split4_test_score': array([     nan, 0.901875,      nan, 0.903125,      nan, 0.903125]),\n",
       " 'mean_test_score': array([     nan, 0.897375,      nan, 0.899   ,      nan, 0.898875]),\n",
       " 'std_test_score': array([       nan, 0.00479909,        nan, 0.00481858,        nan,\n",
       "        0.00471699]),\n",
       " 'rank_test_score': array([4, 3, 5, 1, 6, 2])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели после подборки параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1604   62]\n",
      " [ 140  194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1666\n",
      "           1       0.76      0.58      0.66       334\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.84      0.77      0.80      2000\n",
      "weighted avg       0.89      0.90      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество модели, по сравнению с предыдущей, никак не улучшилось."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
